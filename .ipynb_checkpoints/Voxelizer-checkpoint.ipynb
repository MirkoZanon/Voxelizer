{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a17f07e-e09c-4fba-9b41-87ffe1d7bfaa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from PIL import Image\n",
    "import os\n",
    "\n",
    "import vodex as vx\n",
    "import numan as nu\n",
    "import tifffile as tif\n",
    "from patchify import patchify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8010d",
   "metadata": {},
   "source": [
    "## create test 4D movie: t=20 x,y,z=10x10x10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abba656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movie = np.zeros((20,10,10,10), dtype=np.int16)\n",
    "test_movie[:,0:2,3:5,2:4]=1\n",
    "test_movie[:,0:2,3:5,4:6]=10\n",
    "test_movie = test_movie*np.arange(20)[:,None,None,None]\n",
    "#print(test_movie)\n",
    "tif.imwrite('test_movie.tif', test_movie.astype(np.int16), shape=(20,10,10,10), \n",
    "            metadata={'axes': 'TZYX'}, imagej=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a592dbe",
   "metadata": {},
   "source": [
    "## create test 3D mask 10x10x10 (2 masks, 1&2 values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e9e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.zeros((10,10,10), dtype=np.int16)\n",
    "test_data[0:5,0:5,0:5]=1\n",
    "test_data[5:,5:,5:]=2\n",
    "tif.imwrite('test_mask.tif', test_data, imagej=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f00b26",
   "metadata": {},
   "source": [
    "# define class Voxelizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bddc2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voxelizer:\n",
    "    \n",
    "    def __init__(self, mask_file, superVoxel_size, roi_id):\n",
    "        self.SV_size = superVoxel_size # order: z,y,x\n",
    "        self.roi_id = roi_id\n",
    "        # define binary mask for the stack volume\n",
    "        self.mask = self._load_mask(mask_file)\n",
    "        # define mask bounding box on mask\n",
    "        self.bbox_lim = self._get_bbox()\n",
    "        # define normalization factors for super voxels (SV) inside a mask (normalization = number of mask voxels in a SV)\n",
    "        self.SV_normalization = self._get_mask_in_SV()\n",
    "        self.cell_avg = None\n",
    "        \n",
    "    def process_movie(self, experiment, n_vol):\n",
    "        vol_count = 0\n",
    "        tot_vol = experiment.n_volumes\n",
    "        self.cell_avg = np.zeros((tot_vol, self.SV_normalization.shape[0],self.SV_normalization.shape[1],self.SV_normalization.shape[2]))\n",
    "        chuncks = experiment.batch_volumes(n_vol, full_only=True, overlap=0)\n",
    "        for chunck in chuncks:\n",
    "            data = experiment.load_volumes(chunck, verbose=False)\n",
    "            # cycle across volumes (i.e. time points)\n",
    "            for vol in data:\n",
    "                masked_data = vol*self.mask\n",
    "                bbox_data = masked_data[self.bbox_lim[0]:self.bbox_lim[1], self.bbox_lim[2]:self.bbox_lim[3], self.bbox_lim[4]:self.bbox_lim[5]]\n",
    "                data_patched = patchify(bbox_data, self.SV_size, step=self.SV_size)\n",
    "                sum_data = np.zeros((data_patched.shape[0],data_patched.shape[1],data_patched.shape[2]))\n",
    "                # cycle across all aptches in a volume\n",
    "                for z in np.arange(data_patched.shape[0]):\n",
    "                    for y in np.arange(data_patched.shape[1]):\n",
    "                        for x in np.arange(data_patched.shape[2]):\n",
    "                           sum_data[z,y,x] = sum(sum(sum(data_patched[z,y,x,:,:,:])))\n",
    "                # this is a matrix of avg intensity values for all patches in the specific volume\n",
    "                avg_data = sum_data/self.SV_normalization\n",
    "                #print(avg_data)\n",
    "                self._save_to_cell_table(avg_data, vol_count)\n",
    "                vol_count+=1\n",
    "        # this is only last element process, no real meaning to extract, only to test\n",
    "        return avg_data\n",
    "    \n",
    "    def create_cell_signal_table(self, experiment):\n",
    "        if self.cell_avg.any() != None:\n",
    "            cell_avg_matrix = self.cell_avg.reshape(experiment.n_volumes,-1)\n",
    "            return cell_avg_matrix\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def _load_mask(self, mask_file):\n",
    "        im = tif.imread(mask_file)\n",
    "        np_seg = np.array(im)\n",
    "        roi_mask = np.where(np_seg == self.roi_id, 1, 0)\n",
    "        return roi_mask\n",
    "    \n",
    "    def _get_bbox(self):\n",
    "        bbox_lim = 0, 0, 0, 0, 0, 0 # order: z,y,x\n",
    "        if len(self.mask) != 0 and len(self.mask[2]) != 0 and len(self.mask[1]) != 0 and len(self.mask[0]) != 0:\n",
    "            temporal_indicies = np.where(np.any(self.mask, axis=0))[0]\n",
    "            vertical_indicies = np.where(np.any(self.mask, axis=1))[0]\n",
    "            horizontal_indicies = np.where(np.any(self.mask, axis=2))[0]\n",
    "            z_min, z_max = temporal_indicies[[0, -1]]\n",
    "            y_min, y_max = vertical_indicies[[0, -1]]\n",
    "            x_min, x_max = horizontal_indicies[[0, -1]]\n",
    "            z_max += 1\n",
    "            y_max += 1\n",
    "            x_max += 1\n",
    "            \n",
    "            # adjust bounding box to fit an exact number of super voxels\n",
    "            if self.SV_size != None:\n",
    "                if (x_max-x_min)%self.SV_size[2] != 0:\n",
    "                    x_max += self.SV_size[2]-((x_max-x_min)%self.SV_size[2])\n",
    "                if (y_max-y_min)%self.SV_size[1] != 0:\n",
    "                    y_max += self.SV_size[1]-((y_max-y_min)%self.SV_size[1])\n",
    "                if (z_max-z_min)%self.SV_size[0] != 0:\n",
    "                    z_max += self.SV_size[0]-((z_max-z_min)%self.SV_size[0])\n",
    "            \n",
    "            # adjust bounding box to fit volume dimentions (if it exceed it is shifted back)\n",
    "            if z_max > self.mask.shape[0]:\n",
    "                z_min -= (z_max - self.mask.shape[0])\n",
    "                z_max -= (z_max - self.mask.shape[0])\n",
    "            if y_max > self.mask.shape[1]:\n",
    "                y_min -= (y_max - self.mask.shape[1])\n",
    "                y_max -= (y_max - self.mask.shape[1])\n",
    "            if x_max > self.mask.shape[2]:\n",
    "                x_min -= (x_max - self.mask.shape[2])\n",
    "                x_max -= (x_max - self.mask.shape[2])\n",
    "                \n",
    "            bbox_lim = [x_min, x_max, y_min, y_max, z_min, z_max]\n",
    "        else:\n",
    "            # Handle error case where segmentation image cannot be read or is empty\n",
    "            print(\"Error: Segmentation image could not be read or is empty.\")           \n",
    "        return bbox_lim\n",
    "    \n",
    "    def _get_mask_in_SV(self):\n",
    "        bbox = self.mask[self.bbox_lim[0]:self.bbox_lim[1],self.bbox_lim[2]:self.bbox_lim[3],self.bbox_lim[4]:self.bbox_lim[5]]\n",
    "        patches = patchify(bbox, self.SV_size, step=self.SV_size)\n",
    "        normalization_voxels = np.zeros((patches.shape[0],patches.shape[1],patches.shape[2]))\n",
    "        for z in np.arange(patches.shape[0]):\n",
    "            for y in np.arange(patches.shape[1]):\n",
    "                for x in np.arange(patches.shape[2]):\n",
    "                    normalization_voxels[z,y,x] = sum(sum(sum(patches[z,y,x,:,:,:])))\n",
    "        return normalization_voxels\n",
    "    \n",
    "    def _save_to_cell_table(self, data, index):   \n",
    "        for z in np.arange(data.shape[0]):\n",
    "            for y in np.arange(data.shape[1]):\n",
    "                for x in np.arange(data.shape[2]):\n",
    "                    self.cell_avg[index,z,y,x]=data[z,y,x]\n",
    "                \n",
    "    #def _save_to_file(self, data, index):   \n",
    "    #    for z in np.arange(data.shape[0]):\n",
    "    #        for y in np.arange(data.shape[1]):\n",
    "    #            for x in np.arange(data.shape[2]):\n",
    "    #                path = 'patched_average_signal/patch'+str(z)+str(y)+str(x)+'/'\n",
    "    #                check_folder = os.path.isdir(path)\n",
    "    #                if not check_folder:\n",
    "    #                    os.makedirs(path)\n",
    "    #                tif.imwrite(path+'vol'+str(index)+'.tif', data.astype(np.int16), imagej=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cdf91",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a7c9cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files information :\n",
      "\n",
      "files directory: test_movie\n",
      "files [number of frames]: \n",
      "0) test_movie.tif [200]\n",
      "\n",
      "Total frames : 200\n",
      "Volumes start on frame : 0\n",
      "Total good volumes : 20\n",
      "Frames per volume : 10\n",
      "Tailing frames (not a full volume , at the end) : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_dir = \"test_movie\"\n",
    "mask_file = \"test_mask.tif\"\n",
    "superVoxel_size = [2,2,2] # order: z,y,x\n",
    "#roi_id = [1,2]\n",
    "n_vol_batch = 3\n",
    "\n",
    "frames_per_volume = 10\n",
    "starting_slice = 0\n",
    "experiment = vx.Experiment.from_dir(movie_dir, frames_per_volume, starting_slice, verbose=True)\n",
    "\n",
    "voxelizer = Voxelizer(mask_file, superVoxel_size, 1) #select mask, the test checks fit mask 1\n",
    "voxelizer.process_movie(experiment, n_vol_batch)\n",
    "final_cell_matrix = voxelizer.create_cell_signal_table(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c6dea3",
   "metadata": {},
   "source": [
    "### test _load_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73bcef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = voxelizer._load_mask(mask_file)\n",
    "print(mask.shape)\n",
    "sum(sum(sum(mask))) == 125"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db958296",
   "metadata": {},
   "source": [
    "### test _get_bbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdfbca1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 10, 4, 10, 4, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_lim = voxelizer._get_bbox()\n",
    "print(bbox_lim)\n",
    "bbox_lim == [0, 6, 0, 6, 0, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e8d46",
   "metadata": {},
   "source": [
    "### test _get_mask_in_SV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c071ed62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization_voxels = voxelizer._get_mask_in_SV()\n",
    "# this is true for test mask 1\n",
    "normalization_voxels == [[[8.,8.,4.],[8.,8.,4.],[4.,4.,2.]],[[8.,8.,4.],[8.,8.,4.],[4.,4.,2.]],[[4.,4.,2.],[4.,4.,2.],[2.,2.,1.]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e90db",
   "metadata": {},
   "source": [
    "### test process_movie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "358467fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_avg = voxelizer.process_movie(experiment, n_vol_batch)\n",
    "# this is true for test mask 1\n",
    "last_avg == [[[0.,0.,0.],[0.,9.5,95.],[0.,19.,190.]],[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]],[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0546a266",
   "metadata": {},
   "source": [
    "### test create_cell_signal_table(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e6ff65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cell_matrix = voxelizer.create_cell_signal_table(experiment)\n",
    "final_cell_matrix.shape == (20,27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ff52b",
   "metadata": {},
   "source": [
    "# Run complete analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca852572",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_file = \"test_movie.test_movie.tif\"\n",
    "mask_file = \"test_mask.tif\"\n",
    "superVoxel_size = [2,2,2]\n",
    "roi_id = [1,2]\n",
    "n_vol_batch = 5\n",
    "\n",
    "frames_per_volume = 10\n",
    "starting_slice = 0\n",
    "experiment = vx.Experiment.from_dir(path, frames_per_volume, starting_slice, verbose=True)\n",
    "\n",
    "voxelizer = Voxelizer(mask_file, superVoxel_size, roi_id)\n",
    "voxelizer.process_movie(experiment, n_vol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voxelizer",
   "language": "python",
   "name": "voxelizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
