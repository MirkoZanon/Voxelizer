{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a17f07e-e09c-4fba-9b41-87ffe1d7bfaa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import vodex as vx\n",
    "import numan as nu\n",
    "import tifffile as tif\n",
    "from patchify import patchify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8010d",
   "metadata": {},
   "source": [
    "## create test 4D movie: t=20 x,y,z=10x10x10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abba656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movie = np.zeros((20,10,10,10), dtype=np.int16)\n",
    "test_movie[:,0:2,3:5,2:4]=1\n",
    "test_movie[:,0:2,3:5,4:6]=10\n",
    "test_movie = test_movie*np.arange(20)[:,None,None,None]\n",
    "#print(test_movie)\n",
    "tif.imwrite('test_movie.tif', test_movie.astype(np.int16), shape=(20,10,10,10), \n",
    "            metadata={'axes': 'TZYX'}, imagej=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a592dbe",
   "metadata": {},
   "source": [
    "## create test 3D mask 10x10x10 (2 masks, 1&2 values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e9e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.zeros((10,10,10), dtype=np.int16)\n",
    "test_data[0:5,0:5,0:5]=1\n",
    "test_data[5:,5:,5:]=2\n",
    "tif.imwrite('test_mask.tif', test_data, imagej=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f00b26",
   "metadata": {},
   "source": [
    "# define class Voxelizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bddc2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voxelizer:\n",
    "    \n",
    "    def __init__(self, mask_file, superVoxel_size, roi_id):\n",
    "        self.SV_size = superVoxel_size # order: z,y,x\n",
    "        self.roi_id = roi_id\n",
    "        # define binary mask for the stack volume\n",
    "        self.mask = self._load_mask(mask_file)\n",
    "        # define mask bounding box on mask\n",
    "        self.bbox_lim = self._get_bbox()\n",
    "        # define normalization factors for super voxels (SV) inside a mask (normalization = number of mask voxels in a SV)\n",
    "        self.SV_normalization = self._get_mask_in_SV()\n",
    "        self.cell_avg = None\n",
    "        \n",
    "    def process_movie(self, experiment, n_vol): #patchify in SV and calculated avg signal inside each SV\n",
    "        vol_count = 0\n",
    "        tot_vol = experiment.n_volumes\n",
    "        self.cell_avg = np.zeros((tot_vol, self.SV_normalization.shape[0],self.SV_normalization.shape[1],self.SV_normalization.shape[2]))\n",
    "        chuncks = experiment.batch_volumes(n_vol, full_only=True, overlap=0)\n",
    "        for chunck in chuncks:\n",
    "            data = experiment.load_volumes(chunck, verbose=False)\n",
    "            # cycle across volumes (i.e. time points)\n",
    "            for vol in data:\n",
    "                masked_data = vol*self.mask\n",
    "                bbox_data = masked_data[self.bbox_lim[0]:self.bbox_lim[1], self.bbox_lim[2]:self.bbox_lim[3], self.bbox_lim[4]:self.bbox_lim[5]]\n",
    "                data_patched = patchify(bbox_data, self.SV_size, step=self.SV_size)\n",
    "                sum_data = np.zeros((data_patched.shape[0],data_patched.shape[1],data_patched.shape[2]))\n",
    "                # cycle across all patches in a volume\n",
    "                for z in np.arange(data_patched.shape[0]):\n",
    "                    for y in np.arange(data_patched.shape[1]):\n",
    "                        for x in np.arange(data_patched.shape[2]):\n",
    "                           sum_data[z,y,x] = sum(sum(sum(data_patched[z,y,x,:,:,:])))\n",
    "                # this is a matrix of avg intensity values for all patches in the specific volume\n",
    "                avg_data = sum_data/self.SV_normalization\n",
    "                #print(avg_data)\n",
    "                self._save_to_cell_table(avg_data, vol_count)\n",
    "                vol_count+=1\n",
    "        # this is only last element process, no real meaning to extract, only to test\n",
    "        return avg_data\n",
    "    \n",
    "    def create_cell_signal_table(self, experiment): # from patched avg data, create a 2D table timeXcells\n",
    "        if self.cell_avg.any() != None:\n",
    "            cell_avg_matrix = self.cell_avg.reshape(experiment.n_volumes,-1)\n",
    "            return cell_avg_matrix  # volumes(time) X SV(cells)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def save_ROI_to_file(self, path):   \n",
    "        tif.imwrite(path+'ROI'+str(self.roi_id)+'.tif', self.cell_avg.astype(np.int16), imagej=True)\n",
    "        \n",
    "    def _load_mask(self, mask_file):\n",
    "        im = tif.imread(mask_file)\n",
    "        np_seg = np.array(im)\n",
    "        roi_mask = np.where(np_seg == self.roi_id, 1, 0)\n",
    "        return roi_mask\n",
    "    \n",
    "    def _get_bbox(self):\n",
    "        bbox_lim = 0, 0, 0, 0, 0, 0 # order: z,y,x\n",
    "        if len(self.mask) != 0 and len(self.mask[2]) != 0 and len(self.mask[1]) != 0 and len(self.mask[0]) != 0:\n",
    "            temporal_indicies = np.where(np.any(self.mask, axis=0))[0]\n",
    "            vertical_indicies = np.where(np.any(self.mask, axis=1))[0]\n",
    "            horizontal_indicies = np.where(np.any(self.mask, axis=2))[0]\n",
    "            z_min, z_max = temporal_indicies[[0, -1]]\n",
    "            y_min, y_max = vertical_indicies[[0, -1]]\n",
    "            x_min, x_max = horizontal_indicies[[0, -1]]\n",
    "            z_max += 1\n",
    "            y_max += 1\n",
    "            x_max += 1\n",
    "            \n",
    "            # adjust bounding box to fit an exact number of super voxels\n",
    "            if self.SV_size != None:\n",
    "                if (x_max-x_min)%self.SV_size[2] != 0:\n",
    "                    x_max += self.SV_size[2]-((x_max-x_min)%self.SV_size[2])\n",
    "                if (y_max-y_min)%self.SV_size[1] != 0:\n",
    "                    y_max += self.SV_size[1]-((y_max-y_min)%self.SV_size[1])\n",
    "                if (z_max-z_min)%self.SV_size[0] != 0:\n",
    "                    z_max += self.SV_size[0]-((z_max-z_min)%self.SV_size[0])\n",
    "            \n",
    "            # adjust bounding box to fit volume dimentions (if it exceed it is shifted back)\n",
    "            if z_max > self.mask.shape[0]:\n",
    "                z_min -= (z_max - self.mask.shape[0])\n",
    "                z_max -= (z_max - self.mask.shape[0])\n",
    "            if y_max > self.mask.shape[1]:\n",
    "                y_min -= (y_max - self.mask.shape[1])\n",
    "                y_max -= (y_max - self.mask.shape[1])\n",
    "            if x_max > self.mask.shape[2]:\n",
    "                x_min -= (x_max - self.mask.shape[2])\n",
    "                x_max -= (x_max - self.mask.shape[2])\n",
    "                \n",
    "            bbox_lim = [x_min, x_max, y_min, y_max, z_min, z_max]\n",
    "        else:\n",
    "            # Handle error case where segmentation image cannot be read or is empty\n",
    "            print(\"Error: Segmentation image could not be read or is empty.\")           \n",
    "        return bbox_lim\n",
    "    \n",
    "    def _get_mask_in_SV(self):\n",
    "        bbox = self.mask[self.bbox_lim[0]:self.bbox_lim[1],self.bbox_lim[2]:self.bbox_lim[3],self.bbox_lim[4]:self.bbox_lim[5]]\n",
    "        patches = patchify(bbox, self.SV_size, step=self.SV_size)\n",
    "        normalization_voxels = np.zeros((patches.shape[0],patches.shape[1],patches.shape[2]))\n",
    "        for z in np.arange(patches.shape[0]):\n",
    "            for y in np.arange(patches.shape[1]):\n",
    "                for x in np.arange(patches.shape[2]):\n",
    "                    normalization_voxels[z,y,x] = sum(sum(sum(patches[z,y,x,:,:,:])))\n",
    "        return normalization_voxels\n",
    "    \n",
    "    def _save_to_cell_table(self, data, index):   \n",
    "        for z in np.arange(data.shape[0]):\n",
    "            for y in np.arange(data.shape[1]):\n",
    "                for x in np.arange(data.shape[2]):\n",
    "                    self.cell_avg[index,z,y,x]=data[z,y,x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cdf91",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7c9cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files information :\n",
      "\n",
      "files directory: test_movie\n",
      "files [number of frames]: \n",
      "0) test_movie.tif [200]\n",
      "\n",
      "Total frames : 200\n",
      "Volumes start on frame : 0\n",
      "Total good volumes : 20\n",
      "Frames per volume : 10\n",
      "Tailing frames (not a full volume , at the end) : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_dir = \"test_movie\"\n",
    "mask_file = \"test_mask.tif\"\n",
    "superVoxel_size = [2,2,2] # order: z,y,x\n",
    "roi_id = 1 #select mask, the test checks fit mask 1, not 2\n",
    "n_vol_batch = 3\n",
    "\n",
    "frames_per_volume = 10\n",
    "starting_slice = 0\n",
    "experiment = vx.Experiment.from_dir(movie_dir, frames_per_volume, starting_slice, verbose=True)\n",
    "\n",
    "voxelizer = Voxelizer(mask_file, superVoxel_size, roi_id)\n",
    "#voxelizer.process_movie(experiment, n_vol_batch)\n",
    "#final_cell_matrix = voxelizer.create_cell_signal_table(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c6dea3",
   "metadata": {},
   "source": [
    "### test _load_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73bcef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = voxelizer._load_mask(mask_file)\n",
    "print(mask.shape)\n",
    "sum(sum(sum(mask))) == 125"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db958296",
   "metadata": {},
   "source": [
    "### test _get_bbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdfbca1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 6, 0, 6, 0, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_lim = voxelizer._get_bbox()\n",
    "print(bbox_lim)\n",
    "bbox_lim == [0, 6, 0, 6, 0, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e8d46",
   "metadata": {},
   "source": [
    "### test _get_mask_in_SV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c071ed62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization_voxels = voxelizer._get_mask_in_SV()\n",
    "# this is true for test mask 1\n",
    "normalization_voxels == [[[8.,8.,4.],[8.,8.,4.],[4.,4.,2.]],[[8.,8.,4.],[8.,8.,4.],[4.,4.,2.]],[[4.,4.,2.],[4.,4.,2.],[2.,2.,1.]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e90db",
   "metadata": {},
   "source": [
    "### test process_movie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "358467fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'data_patched' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m last_avg \u001b[38;5;241m=\u001b[39m \u001b[43mvoxelizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_movie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_vol_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# this is true for test mask 1\u001b[39;00m\n\u001b[1;32m      3\u001b[0m last_avg \u001b[38;5;241m==\u001b[39m [[[\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m],[\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m9.5\u001b[39m,\u001b[38;5;241m95.\u001b[39m],[\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m19.\u001b[39m,\u001b[38;5;241m190.\u001b[39m]],[[\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m],[\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m],[\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m]],[[\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m],[\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m],[\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m0.\u001b[39m]]]\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mVoxelizer.process_movie\u001b[0;34m(self, experiment, n_vol)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((tot_vol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSV_normalization\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSV_normalization\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSV_normalization\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     18\u001b[0m chuncks \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39mbatch_volumes(n_vol, full_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m sum_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[43mdata_patched\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],data_patched\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],data_patched\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunck \u001b[38;5;129;01min\u001b[39;00m chuncks:\n\u001b[1;32m     21\u001b[0m     data \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39mload_volumes(chunck, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'data_patched' referenced before assignment"
     ]
    }
   ],
   "source": [
    "last_avg = voxelizer.process_movie(experiment, n_vol_batch)\n",
    "# this is true for test mask 1\n",
    "last_avg == [[[0.,0.,0.],[0.,9.5,95.],[0.,19.,190.]],[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]],[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0546a266",
   "metadata": {},
   "source": [
    "### test create_cell_signal_table(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e6ff65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cell_matrix = voxelizer.create_cell_signal_table(experiment)\n",
    "final_cell_matrix.shape == (20,27) # volumes(time) X SV(cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a860e2",
   "metadata": {},
   "source": [
    "### test save_ROI_to_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684dc780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_movie/ROI_patched/ folder already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 3, 3, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = (movie_file+'/ROI_patched/')\n",
    "check_folder = os.path.isdir(path)\n",
    "# If folder doesn't exist, then create it.\n",
    "if not check_folder:\n",
    "    os.makedirs(path)\n",
    "    print(\"created folder : \", path)\n",
    "else:\n",
    "    print(path, \"folder already exists.\")\n",
    "voxelizer.save_ROI_to_file(movie_file+'/ROI_patched/')\n",
    "voxelizer.cell_avg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ff52b",
   "metadata": {},
   "source": [
    "# Run complete analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca852572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files information :\n",
      "\n",
      "files directory: test_movie\n",
      "files [number of frames]: \n",
      "0) test_movie.tif [200]\n",
      "\n",
      "Total frames : 200\n",
      "Volumes start on frame : 0\n",
      "Total good volumes : 20\n",
      "Frames per volume : 10\n",
      "Tailing frames (not a full volume , at the end) : 0\n",
      "\n",
      "(20, 27)\n",
      "test_movie/ROI_patched/ folder already exists.\n"
     ]
    }
   ],
   "source": [
    "movie_file = \"test_movie\"\n",
    "mask_file = \"test_mask.tif\"\n",
    "superVoxel_size = [2,2,2]\n",
    "roi_id = 1\n",
    "n_vol_batch = 5\n",
    "\n",
    "frames_per_volume = 10\n",
    "starting_slice = 0\n",
    "experiment = vx.Experiment.from_dir(movie_file, frames_per_volume, starting_slice, verbose=True)\n",
    "\n",
    "voxelizer = Voxelizer(mask_file, superVoxel_size, roi_id)\n",
    "voxelizer.process_movie(experiment, n_vol_batch)\n",
    "final_cell_matrix = voxelizer.create_cell_signal_table(experiment)\n",
    "print(final_cell_matrix.shape) # volumes(time) X SV(cells)\n",
    "\n",
    "path = (movie_file+'/ROI_patched/')\n",
    "check_folder = os.path.isdir(path)\n",
    "# If folder doesn't exist, then create it.\n",
    "if not check_folder:\n",
    "    os.makedirs(path)\n",
    "    print(\"created folder : \", path)\n",
    "else:\n",
    "    print(path, \"folder already exists.\")\n",
    "voxelizer.save_ROI_to_file(movie_file+'/ROI_patched/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voxelizer",
   "language": "python",
   "name": "voxelizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
