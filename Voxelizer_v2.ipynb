{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import vodex as vx\n",
    "import numan as nu\n",
    "import tifffile as tif\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "from typing import Union, List, Optional, Tuple, Dict, Any\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voxelizer:\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute average signal value (of a 4D matrix of fluorescence imaging data: fluorescence intensity at t X z X y X x) across Super Voxels (3D voxels with user-defined size)\n",
    "    inside a ROI (user-defined mask -multiple ROIs can be provided by providing different integer IDs into the mask).\n",
    "    Note: the mask should have the same 3D dimentions as a dataset volume and consist of integer values corresponding to voxels of interest \n",
    "    for the different ROIs; the 3D Super Voxel size should be no bigger than the dataset volume. \n",
    "\n",
    "    Args:\n",
    "        mask_file: strig of a .tif file with the same 3D dimentions of the dataset volume and integer values correspondent to the voxels of the different ROIs\n",
    "        superVoxel_size: a 1x3 array [z,y,x] with the dimentions of the Super Voxel (group of voxels to be averaged and considered as single unit)\n",
    "        roi_id: an integer value correpsondent to the ROI to be analysed (to be patchified in SVs and compute its SV avg); this value is the \n",
    "            integer value of the voxels in mask_file correpsondent to the ROI of interest\n",
    "\n",
    "    Attributes:\n",
    "        SV_size: a 1x3 array [z,y,x] with the dimentions of the Super Voxel (group of voxels to be averaged and considered as single unit)\n",
    "        mask: an numpy array with the same 3D dimentions of the dataset volume with integer values correspondent to the voxels of the different ROIs\n",
    "        padded_mask: zero padded mask to fit integer number of SVs\n",
    "        all_patches_coordinates: list of [x_min, x_mx, y_min, y_max, z_min, z_max] for each patch in the mask (list of list)\n",
    "        mask_SVs: list of mask patches values correspondent to the only ROI of interest\n",
    "        mask_patches_coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mask_file: str, superVoxel_size: npt.NDArray, roi_id: int):\n",
    "        self.SV_size = superVoxel_size # order: z,y,x\n",
    "        # load multi-ROI mask from .tif\n",
    "        self.mask = self._load_mask(mask_file)\n",
    "        # zero pad mask by SV size\n",
    "        self.padded_mask = self._zero_pad_matrix_in_space(self.mask)\n",
    "        # patchify mask through SV and get locations (get list of patches indeces [i_SV_z, i_SV_y, i_SV_x] for each SV -list of lists-)\n",
    "        patches_locations = self._get_patches_locations()\n",
    "        # get coordinates of each patch location\n",
    "        self.all_patches_coordinates = self._get_patches_coordinates(patches_locations)\n",
    "        # extract patches related to a specific ROI\n",
    "        self.mask_SVs, self.mask_patches_coordinates = self._get_ROI_patches(roi_id)\n",
    "\n",
    "    def _load_mask(self, mask_file: str) -> npt.NDArray: \n",
    "        mask = tif.imread(mask_file)\n",
    "        return mask\n",
    "    \n",
    "    def _zero_pad_matrix_in_space(self, data: npt.NDArray) -> npt.NDArray:\n",
    "        if data.ndim == 3:\n",
    "            padded = np.zeros((data.shape[0]+self.SV_size[0]-data.shape[0]%self.SV_size[0], data.shape[1]+self.SV_size[1]-data.shape[1]%self.SV_size[1], data.shape[2]+self.SV_size[2]-data.shape[2]%self.SV_size[2]))\n",
    "            padded[0:data.shape[0], 0:data.shape[1], 0:data.shape[2]] = data\n",
    "        elif data.ndim == 4:\n",
    "            padded = np.zeros((data.shape[0]*(data.shape[1]+self.SV_size[0]-data.shape[1]%self.SV_size[0])*(data.shape[2]+self.SV_size[1]-data.shape[2]%self.SV_size[1])*(data.shape[3]+self.SV_size[2]-data.shape[3]%self.SV_size[2])))\n",
    "            padded = np.reshape(padded,(data.shape[0], data.shape[1]+self.SV_size[0]-data.shape[1]%self.SV_size[0], data.shape[2]+self.SV_size[1]-data.shape[2]%self.SV_size[1], data.shape[3]+self.SV_size[2]-data.shape[3]%self.SV_size[2]))\n",
    "            padded[:, 0:data.shape[1], 0:data.shape[2], 0:data.shape[3]] = data \n",
    "        else:\n",
    "             print('Error: data provided to pad is of inconsistent dimention; should be 3D or 4D matrix (z,y,x) or (t,z,y,x)')\n",
    "        return padded\n",
    "\n",
    "    def _get_patches_locations(self) -> List[List[int]]:\n",
    "        locations = []\n",
    "        for i_SV_z in np.arange(int(self.padded_mask.shape[0]/self.SV_size[0])):\n",
    "            for i_SV_y in np.arange(int(self.padded_mask.shape[1]/self.SV_size[1])):\n",
    "                for i_SV_x in np.arange(int(self.padded_mask.shape[2]/self.SV_size[2])):\n",
    "                    locations.append([i_SV_z, i_SV_y, i_SV_x])\n",
    "        return locations\n",
    "    \n",
    "    def _get_patches_coordinates(self, patch_locations: List[List[int]]) -> List[List[int]]: #patch_location = [[i_SV_z, i_SV_y, i_SV_x],[],[],...]\n",
    "        coords = []\n",
    "        for i_SV in patch_locations:\n",
    "            i_SV_z, i_SV_y, i_SV_x = i_SV\n",
    "            z_min = i_SV_z*self.SV_size[0]\n",
    "            z_max = (i_SV_z+1)*self.SV_size[0]\n",
    "            y_min = i_SV_y*self.SV_size[1]\n",
    "            y_max = (i_SV_y+1)*self.SV_size[1]\n",
    "            x_min = i_SV_x*self.SV_size[2]\n",
    "            x_max = (i_SV_x+1)*self.SV_size[2]\n",
    "            coords.append([z_min, z_max, y_min, y_max, x_min, x_max])\n",
    "        return coords\n",
    "    \n",
    "    def _get_ROI_patches(self, roi_id: int) -> Union[List[List[int]], List[List[int]]]:\n",
    "        # extract patches related to a specific ROI\n",
    "        mask_SVs = [] # 'good' patches (within mask)\n",
    "        mask_patches_coordinates = {'z_min':[], 'z_max':[], 'y_min':[], 'y_max':[], 'x_min':[], 'x_max':[]}\n",
    "        for coords in self.all_patches_coordinates:\n",
    "            my_patch = self._get_patch(self.padded_mask, coords) == roi_id\n",
    "            if np.sum(my_patch) > 0:\n",
    "                        mask_SVs.append(my_patch)\n",
    "                        z_min, z_max, y_min, y_max, x_min, x_max = coords\n",
    "                        for key in mask_patches_coordinates.keys():\n",
    "                             mask_patches_coordinates[key].append(locals()[key])\n",
    "        return mask_SVs, mask_patches_coordinates\n",
    "    \n",
    "    def process_movie(self, experiment: vx.Experiment, batch_size: int) -> Dict: #patchify in SV and calculated avg signal inside each SV\n",
    "        \"\"\"\n",
    "        Calculate mean signal values inside SV within the ROI\n",
    "\n",
    "        Args:\n",
    "            experiment: Vodex Experiment object\n",
    "            batch_size: number of movie volumes (time points) to be loaded and process at a time\n",
    "\n",
    "        Returns:\n",
    "            sv_signal: list (SV) of list (time avg) with avg signals for each SV in ROI\n",
    "        \"\"\"\n",
    "        sv_signal = {f\"sv_{isv}\":[] for isv in range(len(self.mask_SVs))}\n",
    "        chuncks = experiment.batch_volumes(batch_size, full_only=True, overlap=0)\n",
    "        for chunck in chuncks:\n",
    "            data = experiment.load_volumes(chunck, verbose=False)\n",
    "            #zero pad dataset\n",
    "            padded_data = self._zero_pad_matrix_in_space(data)\n",
    "            for i_patch in range(len(self.mask_SVs)):\n",
    "                coords = [val[i_patch] for val in self.mask_patches_coordinates.values()]\n",
    "                # cut dataset around SV\n",
    "                data_SV = self._get_patch(padded_data, coords)\n",
    "                # apply mask to SV and get avg signal\n",
    "                data_SV_avg_on_mask = self._get_avg_masked_signal(data_SV, self.mask_SVs[i_patch])\n",
    "                sv_signal[f\"sv_{i_patch}\"].extend(data_SV_avg_on_mask)\n",
    "        return sv_signal\n",
    "\n",
    "    def _get_patch(self, data, patch_coord: List[int]) -> npt.NDArray:\n",
    "        z_min, z_max, y_min, y_max, x_min, x_max = patch_coord\n",
    "        if data.ndim == 3:\n",
    "            patch = data[z_min:z_max, y_min:y_max, x_min:x_max]\n",
    "        elif data.ndim == 4:\n",
    "            patch = data[:,z_min:z_max, y_min:y_max, x_min:x_max]\n",
    "        else:\n",
    "             print('Error: data provided to pad is of inconsistent dimention; should be 3D or 4D matrix (z,y,x) or (t,z,y,x)')\n",
    "        return patch\n",
    "    \n",
    "    def _get_avg_masked_signal(self, data_patched: npt.NDArray, mask_patched: npt.NDArray) -> npt.NDArray:  \n",
    "        data_mask_SV = data_patched*mask_patched\n",
    "        avg_SV = np.sum(data_mask_SV, axis=(1,2,3))/np.sum(mask_patched)\n",
    "        return avg_SV\n",
    "\n",
    "    def create_signal_df(self, sv_signal: Dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create dataframe with avg values for all SV in ROI in time\n",
    "\n",
    "        Args:\n",
    "            sv_signal: dictionary of avg signals from voxelizer.process_movie()\n",
    "\n",
    "        Returns:\n",
    "            final_cell_df: panda dataframe with avg signals for each SV in ROI in time\n",
    "        \"\"\"\n",
    "        final_cell_df =  pd.DataFrame.from_dict(sv_signal)\n",
    "        return final_cell_df\n",
    "    \n",
    "    def create_coordinates_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create dataframe with coordinates for all SV in ROI\n",
    "\n",
    "        Returns:\n",
    "            final_coord_df: panda dataframe with coordinates for each SV in ROI\n",
    "        \"\"\"\n",
    "        coords = self.mask_patches_coordinates\n",
    "        coord_df = pd.DataFrame.from_dict(coords)\n",
    "        labels = ['sv_'+str(i) for i in range(coord_df.shape[0])]\n",
    "        coord_df.index=labels\n",
    "        final_coord_df = coord_df.T\n",
    "        return final_coord_df\n",
    "    \n",
    "    def create_normalized_signal(self):\n",
    "        return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dir = \"test_movie\"\n",
    "mask_file = \"test_mask.tif\"\n",
    "superVoxel_size = [3,3,3] # order: z,y,x\n",
    "roi_id = 1 #select mask, the test checks fit mask 1, not 2\n",
    "#n_vol_batch = 8\n",
    "\n",
    "frames_per_volume = 10\n",
    "starting_slice = 0\n",
    "\n",
    "experiment = vx.Experiment.from_dir(movie_dir, frames_per_volume, starting_slice, verbose=False)\n",
    "\n",
    "voxelizer = Voxelizer(mask_file, superVoxel_size, roi_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = voxelizer._load_mask(mask_file)\n",
    "print(mask.shape)\n",
    "assert np.sum(mask) == 5*5*5*1 + 5*5*5*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12, 12)\n"
     ]
    }
   ],
   "source": [
    "padded_mask = voxelizer._zero_pad_matrix_in_space(mask)\n",
    "print(padded_mask.shape)\n",
    "# this works for SV of size [3,3,3]\n",
    "assert padded_mask.shape == (12,12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "patches_locs = voxelizer._get_patches_locations()\n",
    "#print(patches_locs)\n",
    "assert len(patches_locs) == 4*4*4\n",
    "patches_coords = voxelizer._get_patches_coordinates(patches_locs)\n",
    "# this works for volume of size [10,10,10] and SV of [3,3,3]\n",
    "assert len(patches_coords) == 4*4*4\n",
    "#patched_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "voxelizer._get_ROI_patches(1)\n",
    "print(len(voxelizer.mask_SVs))\n",
    "assert len(voxelizer.mask_SVs) == 8\n",
    "print(voxelizer.mask_SVs[0].shape)\n",
    "assert voxelizer.mask_SVs[0].shape == (3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sv_0  sv_1      sv_2       sv_3  sv_4  sv_5  sv_6  sv_7\n",
      "0    0.0   0.0  0.000000   0.000000   0.0   0.0   0.0   0.0\n",
      "1    0.0   0.0  0.222222   3.666667   0.0   0.0   0.0   0.0\n",
      "2    0.0   0.0  0.444444   7.333333   0.0   0.0   0.0   0.0\n",
      "3    0.0   0.0  0.666667  11.000000   0.0   0.0   0.0   0.0\n",
      "4    0.0   0.0  0.888889  14.666667   0.0   0.0   0.0   0.0\n",
      "5    0.0   0.0  1.111111  18.333333   0.0   0.0   0.0   0.0\n",
      "6    0.0   0.0  1.333333  22.000000   0.0   0.0   0.0   0.0\n",
      "7    0.0   0.0  1.555556  25.666667   0.0   0.0   0.0   0.0\n",
      "8    0.0   0.0  1.777778  29.333333   0.0   0.0   0.0   0.0\n",
      "9    0.0   0.0  2.000000  33.000000   0.0   0.0   0.0   0.0\n",
      "10   0.0   0.0  2.222222  36.666667   0.0   0.0   0.0   0.0\n",
      "11   0.0   0.0  2.444444  40.333333   0.0   0.0   0.0   0.0\n",
      "12   0.0   0.0  2.666667  44.000000   0.0   0.0   0.0   0.0\n",
      "13   0.0   0.0  2.888889  47.666667   0.0   0.0   0.0   0.0\n",
      "14   0.0   0.0  3.111111  51.333333   0.0   0.0   0.0   0.0\n",
      "15   0.0   0.0  3.333333  55.000000   0.0   0.0   0.0   0.0\n",
      "16   0.0   0.0  3.555556  58.666667   0.0   0.0   0.0   0.0\n",
      "17   0.0   0.0  3.777778  62.333333   0.0   0.0   0.0   0.0\n",
      "18   0.0   0.0  4.000000  66.000000   0.0   0.0   0.0   0.0\n",
      "19   0.0   0.0  4.222222  69.666667   0.0   0.0   0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "table = voxelizer.process_movie(experiment, 8)\n",
    "df = voxelizer.create_signal_df(table)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sv_0  sv_1  sv_2  sv_3  sv_4  sv_5  sv_6  sv_7\n",
      "z_min     0     0     0     0     3     3     3     3\n",
      "z_max     3     3     3     3     6     6     6     6\n",
      "y_min     0     0     3     3     0     0     3     3\n",
      "y_max     3     3     6     6     3     3     6     6\n",
      "x_min     0     3     0     3     0     3     0     3\n",
      "x_max     3     6     3     6     3     6     3     6\n"
     ]
    }
   ],
   "source": [
    "df = voxelizer.create_coordinates_df()\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voxelizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
